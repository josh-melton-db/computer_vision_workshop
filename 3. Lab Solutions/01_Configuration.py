# Databricks notebook source
# MAGIC %md 
# MAGIC You may find this series of notebooks at https://github.com/databricks-industry-solutions/computer-vision-foundations. For more information about this solution accelerator, visit https://www.databricks.com/blog/2021/12/17/enabling-computer-vision-applications-with-the-data-lakehouse.html.

# COMMAND ----------

# MAGIC %md The purpose of this notebook is to manage configuration settings for the notebooks in the computer vision solution accelerator. Please adapt these settings as needed to align the notebook deployment with your environment. 

# COMMAND ----------

# DBTITLE 1,Initialize Configuration Variable
if 'config' not in locals(): 
  config = {}

# COMMAND ----------

user = spark.sql('select current_user() as user').collect()[0]['user'].split('@')[0]

# COMMAND ----------

# DBTITLE 1,Storage Settings
config['mount_point'] = '/tmp/cv_foundations/' # location for data files; use a mount path like /mnt/images/ if reading from external storage
config['incoming_image_file_path'] = config['mount_point'] + '/FileStore/computer_vision_workshop'
config['database_root'] = '/tmp/cv_foundations/cv/'
config['raw_image_file_path'] = 's3://db-gtm-industry-solutions/data/rcg/cv/images/' #dbfs:/FileStore/tables/images/images'
config['checkpoint_path'] = config['mount_point'] + 'tmp/image_processing_chkpnt/' # folder where incoming image processing checkpoint resides
config['checkpoint_path_inference'] = config['mount_point'] + 'tmp/image_inference_chkpnt/'
config['checkpoint_path_inference_73'] = config['mount_point'] + 'tmp/image_inference_chkpnt_73/'
config['petastorm_path'] = 'file:///dbfs/tmp/petastorm/cache/' + user # location where to store petastorm cache files
config['input_images_table'] = 'cv.images_' + user
config['scored_images_73_table'] = "cv.scored_images_73_" + user
config['scored_images_table'] = "cv.scored_images_" + user

# COMMAND ----------

# DBTITLE 1,Model Settings
config['tuning_model_name'] = 'cv pytorch tuning ' + user
config['tuned_model_name'] = 'cv pytorch tuned '  + user
config['tuned_model_name_73'] = 'cv pytorch tuned 73 '  + user
config['final_model_name'] = 'cv pytorch final ' + user

# COMMAND ----------

import mlflow
from mlflow.tracking import MlflowClient
useremail = spark.sql('select current_user() as user').collect()[0]['user']
experiment_name = f"/Users/{useremail}/computer_vision_foundations"
mlflow.set_experiment(experiment_name) 
config['experiment_id'] = (
    MlflowClient()
    .get_experiment_by_name(experiment_name) 
    .experiment_id
)

# COMMAND ----------

# MAGIC %md Â© 2021 Databricks, Inc. All rights reserved. The source in this notebook is provided subject to the Databricks License. All included or referenced third party libraries are subject to the licenses set forth below.
